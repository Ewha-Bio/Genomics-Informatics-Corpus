Current Progress of Next Generation Battery of Toxicology Cellular and Molecular Toxicology, and Toxicogenomics.

The detection and the regulation of synthetic chemicals and the establishment of toxicity that may pose a genetic hazard in our environment are subjects of great concern because    of    its    close    correlation    between    environmental contamination    and    human    health.

Since    the    tens    of thousands of man-made chemicals that have been introduced into the environment in the last few decades must also be tested for their damaging effect on DNA, the agents that cause this damage must be identified.

Toxicology has been defined as the qualitative    and quantitative    study    of    the    adverse    effects    of    xenobiotics on    living    organisms.

Moreover,    modern    toxicology    goes beyond the study of the adverse effects of exogenous agents to the study of cellular and molecular effects of toxicants using molecular biological tools.

Toxicology is a multidisciplinary field, and an important science that impacts both environmental health regulation and the development and practice of medicine (Klaassen, 2001).

Classical    toxicological    tools    require    hundreds of animals and provide little information with respect to mechanism(s).

For    example,    descriptive    studies    in    genetically    inbred animals do not explain genetic and biological differences in the human population that influence individual

response to drugs and environmental xenobiotics.

Recently, several new methods for the    detection    of genetic    damages    in    vitro    and    in    vivo    were    introduced according to the rapid progress in toxicology combined with cellular and molecular biology (Ryu, 1999c, 2002a,b).

Among these methods, the single cell gel electrophoresis (comet assay) which can be detected DNA damages in cell level (Mckelvey-Martin et al., 1993; Singh et ai., 1988, 1991, 1994; Ryu et al., 1997; Tice et al., 2000), mouse lymphoma thymidine kinase gene assay (Clive et al., 1983; Ryu et al., 1999b), FISH (fluorescence in situ hybridization) (Hayashi et al., 1994), PRINS (primed in situ hybridization) (Abbo et al., 1993) and transgenic animal and cell line model as a parameter of lac I (Big Blue) (Kohler et al., 1991; Ryu et al., 1998a,b, 1999a, 2000,2001 c) or lac Z (Muta Mouse) (Suzuki et al.

,1993) gene mutation are newly introduced based on cellular and molecular toxicological approaches.

Also, in vivo supravital micronucleus assay with peripheral reticulocytes by using acridine orange fluorescent staining (Hayashi et al., 1990; Ryu et al., 2001b) was introduced instead of mouse bone marrow micronucleus assay.

Moreover, the rapid progress in cellular and molecular biology, like many other branches of biomedical research, toxicology is now experiencing a renaissance fueled by the application of "omic" technologies to gain a better understanding of the    biological    basis    of    toxicology    of    drugs    and    other environmental    factors    (Aederma    and    McGregor,    2002; Hamadeh and Afsari, 2004).

In this review on current toxicology, at first, the rapid progress    of    cellular    and    molecular    toxicological    tools, and then concept, approaches     and     applications     of toxicogenomics will be described.

Since    the    remarkable    progress    in    cell    biology    and biochemistry, the use of cell lines, enzymes, construction of    genes    etc    became    more    easier    to    handle    in    the laboratories.

In this respect, classical toxicology moved to cellular and molecular toxicology at present, and will move to toxicogenomics (Newton etal., 2004) in the near future.

For     example,     genetic     toxicology     has     great changes    in    methodology    and    sensitivity.

Generally,    the carcinogenicity including genotoxicity is one of the potential toxicity that may consider for the human health.

It has been widely assumed that mutation represents at least one step in carcinogenesis.

The evidence supporting this idea is that the majority of mutagens are carcinogens (McCann et al., 1975) and, for at least some compounds,     mutagenic     potency     is     closely     correlated

with carcinogenic potency (Meselson and Russel, 1977).

Moreover, mutagensand certain non-mutageniccarcinogens have also been found to induce chromosomal rearrangement    (Zimmermann,    1971)    which    may    affect carcinogenesis    by    altering    gene    expression,    perhaps    by allowing    the    activation    or    inactivation    of    cellular    cancer genes (Radman etal., 1982).

Several classical genotoxicity assay systems with rapidity and reliability have been introduced and practically applied (Ames et al., 1973; Maron and Ames, 1983; Mersch-Sundermann et al., 1991) for predicting the carcinogenicity of chemicals and also    been    introduced    to    the    evaluation    of    genotoxicity (Ishidate and Odashima, 1977; Radman et a!., 1982; Hayashi et al., 1990, 1994; Ryu et al., 1993a,b, 1997, 1999b) and of antimutagenicity (Sato etal., 1991; Ryu et al., 1993b, 2001b).

Cytogenetic studies on mammalian cells in vivo (Schmid, 1975; Hayashi et al., 1990, 1994) as well as in vitro (Ishidate and Odashima, 1977) have also been widely used    as    a    screening    method    for DNA-attacking substances.

However,    these    kinds    of    toxicity    evaluation    tools cannot elucidate the mode and/or mechanism of actions of chemicals, especially carcinogens and mutagens.

Moreover, many scientists try to develope more precise, convenient and sensitive techniques for the detection of DNA    damages    as    an    index    of    carcinogenicity.

Several new cellular and molecular genotoxicity    assay    systems are summarized briefly as follows.

Single Cell Gel Electrophoresis (Comet) assay: Since Ostling and Johanson (1984) introduced microelectrophoretic technique, Singh etal.

(1988) have modified and improved the microgel electrophoresis technique to evaluate DNA damage in single cells under alkaline conditions.

The comet assay is rapid, sensitive, visual and simple technique to quantify DNA strand breaks in individual cells at least 3 major basic protocols (Ostling and Johanson, 1984; Singh    etal.,    1988,    1991,    1994,    1995; Olive et al., 1993,1994).

If the agent can cause the strand breakage, we can see the extent of tail from the head (nucleus) like comet with staining of fluorescent dyes such as ethidium bromide,    acridine    orange    and    propidium    iodide    etc.

To harmonize comet     assay, International     Workshop     on Genotoxicity Test     Procedure (IWGTP)     was held     at Washington D.C. on March, 1999 by Environmental Mutagen Society supported with OECD.

Our laboratory (Ryu et al., 1997, 2001a, 2002c) also involved in this harmonization and recommended as OECD guideline with Tice etal.

(2000).

General reviews on this technique have been published by Tice et al.

(2000) and Fairbairn etal.

(1995, 1996).

Mouse    lymphoma    thymidine    kinase    gene    assay

(MOLY)    :    MOLY    with    L5178Y    tk+/-    mouse    lymphoma cells     described     by     Clements     (1994),     with     minor modification    (Clive    et    a!.,    1995,    Garriott    et    al.,    1995; Oberly    and    Garriott,    1996;    Ryu    et    al.,    1999b).

The cytotoxicity of chemical was determined by relative survival (RS) after 3 hr treatment at concentrations up to 5,000 ng/ml in the presence and absence of S-9 mixture.

The    highest    concentration    chosen    was    one    with    a 10-20% RS.

Cultures were exposed to the test chemical for 3 hr, then cultured for 2 days before plating in 96-well microtiter plates at 2000 cells/well with trifluorothymidine for mutant selection and at 1.6 cells/well for cell viability.

The number of wells containing colonies was counted on day 12 after plating, and large and small colonies were scored.

Mutation    frequencies    were    analyzed    by    the statistical    package,    Mutant    V2.31    program    (Hazleton, England) in accordance with the UKEMS guidelines.

Supravital staining in vivo micronucleus assay with peripheral reticulocytes : The micronucleus (MN) assay in vivo is a    method devised primarily for    screening chemicals for     chromosome-breaking effects.

In the monitoring of chromosome breakage, the test is at least as sensitive as the metaphase method; in addition it includes effects on the spindle apparatus.

This MN assay using peripheral    blood erythrocytes was introduced by MacGregor et     al., (1980) and developed by Hayashi et al.

(1990, 1994) having more simple and convenient compared to conventional bone marrow assay by the introduction of supravital staining with acridine orange (Ryu et al., 2001 b).

The conventional Giemsa staining method, however, has some disadvantages because not only MNs but also some cell inclusions containing RNA and other acidic materials are stained dark blue by Giemsa; it is occasionally difficult to identify MNs from these inclusions.

Acridine orange metachromatic fluorochrome discriminates between DNA and RNA by green and red fluorescence, respectively.

In vitro cytokinesis-block micronucleus assay : The micronucleus    assays    have    emerged    as    one    of    the preferred methods for assessing chromosome damage because they enable both chromosome loss and chromosome breakage to be measured reliably (Heddle etal., 1983).

Because micronuclei can only be expressed in cells that complete nuclear division a special method was     developed     that     identifies     such     cells     by     their binucleate    appearance    when    blocked    from    performing cytokinesis    by    cytochalasin-B,    a    microfilament-assembly inhibitor.

This assay allows better precision because the data obtained are not confounded by altered cell division kinetics    caused    by    cytotoxicity    of    agents    tested    or sub-optimal cell culture conditions (Fenech etal., 1999).

Transgenic Mutagenesis assay system: The transgenic

mutagenesis    system    is    a    useful    and    powerful    tool    to evaluate the genotoxicity, and it also provides a window of carcinogenesis     and mutagenesis mechanisms of chemicals based     on information such as mutation pattern, frequency, and location in sequence context of the lac I target gene (Gorelick, 1995).

The lac I transgenic Big Blue Rat2 fibroblast cell line carries over 40 copies of lambda shuttle vector (Dycaico et al., 1994) containing lac I gene as a target (Heddle and Tao, 1995; Summers et al., 1989).

The lac I gene, as a mutational target,    is    very    useful    for    the    study    of    the    mutational characteristics of a carcinogen for several reasons.

First, the relatively small size (1,080 bp of coding region) of lac I gene facilitates sequence analysis.

Second, the expression of repressor protein permits a rapid colorimetric assay to screen for mutations.

The mutations induced in the lac I gene can easily be quantified by mutant    frequency    (MF),    and    the    precise    mutation    type and distribution can    quickly be identified by direct sequencing.

Moreover,    considering that mutations in lac I gene induced by chemicals reflect the    effects of mutagens on other endogenous genes such    as proto­ oncogenes     and     tumor     suppressor     genes,     and     that mutations occurred in these genes are the most common events in many types of human cancer (Kohler et al., 1991; Gossen et al., 1989), this assay may provide a powerful tool to predict the mutation spectrum induced in cancer-related genes more accurately (Ryu et al., 1998a,b, 1999a, 2000).

The recent completion of the human genome sequencing project and the push to finish the mouse genome have raised the stakes in science with predictions of disease cures, more effective and safer pharmaceuticals, and a greater understanding of environmental effects on human health.

The impact of human genome projects on toxicological research is high, heralding the emerging technologies of toxicogenomics, proteomics, and bioinformatics (Lovett, 2000; Pollack, 2000) for the future use of these technologies and their impact on drug discovery, safety evaluation, elucidation of pathways of toxicity, and risk assessment.

The basis of toxicogenomics is summarized in Fig.1.

The NIEHS established the National Center for Toxicogenomics(NCT)    in September 2000.

According to the center's mission    statement, its goal is "to use the methodologies and    information of genomics science to significantly improve our understanding of basic biological responses to environmental stressors/ toxicants."

Paul Gilman, who is an assistant administrator for EPA, states that toxicogenomics is a powerful tool

with great promise for risk assessment (Bergeson et al., 2002).

And also, he stressed that EPA encourages and supports continued genomics research as a powerful tool for understanding the molecular basis of toxicity and developing biomarkers of exposure, effects, and susceptibility.

He also mentioned that genomics information is useful in a weight-of-the-evidence approach for human health and ecological risk assessments on a case-by-case basis at this time.

By combining these new "omics" approaches with classical and/or conventional toxicological methods, it is possible to develope the experimental models and strategies to evaluate 1) the diverse structure and properties of various chemicals; 2) the relationship between the time of exposure, dose, and health outcomes; 3) the influence of genetics and behavioral factors; 4) interaction between mutiple components of biological systems in development of toxic responses; 5) intrinsic biological health responses with extremely low concentration for long time exposure, and 6) toxicological responses of compounds at an early stage of the drug discovery process and health risk assessment.

What is Toxicogenomics?

: Toxicogenomics, in a broader sense, is defined as a study of the response of a genome to hazardous substances, using: i) Genomic-scale mRNA    expression    (transcriptomics),    ii)    Cell    and    tissue wide protein expression (proteomics), and iii) Metabolite profiling (metabon/lomics) in combination with bioinformatic methods and conventional toxicology (In a narrow sense, it refers to the use of transcriptomics).

In relation to chemical hazard/risk assessment, this emerging science could provide tools for improving the understanding of mechanism of toxicity, identification of biomarkers for prediction of toxicity and exposure, and possibly alternative methods for chemical screening, hazard and toxicity identification, characterization, and classification.

Approaches and Application of Toxicogenomics: The utilization of these new technologies along with more established genetic approaches such as quantitative real time polymerase chain reaction (QRT-PCR), and the use of genetically altered animalswill dramatically move the field of toxicology forward.

As you know well, the recent    remarkable    advances    in    genomics,    proteomics, and    metabon/lomics,    the    interactions    between    multiple genes, proteins, and pathways can now be investigated with more easy and time-saving ways (Irwin et al., 2004).

cDNA and oligonucleotide microarrays and high-throughput 2-D electrophoresis systems have quickly emerged as the premier tools to enable genomewide analysis of gene expression at the RNA and protein level.

These new    technologies    are    heavily    influencing    drug    discovery and preclinical safety in the biotechnology and pharmaceutical industry (Freeman, 2000, 2004).

Toxicologists are also promoting genomic expression     technologies as a superior    alternative    to    traditional    rodent    bioassays    to identify and assess the safety of chemicals and drug candidates for human safety (Afshari et al., 1999; Nuwaysiref al., 1999; Pennie et al., 2000, 2002; Ryu et al., 2002d).

It is expected that gene expression profiling will identify mechanisms of action that underlie the potential toxicity of chemicals and drug candidates.

Ultimately,    toxicogenomics    (the    integration    of    genomics, bioinformatics, and toxicology) is expected to accelerate drug development (Suter, 2004; Yang et al., 2004), and aid environment ecological (Neumann and Galvez, 2002) and health risk assessment.

In the laboratory, these are    some examples    of questions that researchers will be    able to address    by toxicogenomics    as    follows;    Which    genes    are    regulated upwards or downwards (apoptosis, cellular proliferation, metabolism, communication and cell adhesion, etc.)

following an exposure to mercury, PCBs or triazines pesticides?

Is the response similar in the liver, lung, testes, ovaries and brain?

Are the responses of animal and cell models comparable to humans?

The network is also particularly interested in the genetic factors responsible for environmental contaminant-induced breast cancers, unfavorable pregnancy outcomes, and children’s health.

The    approaches    in    the    commercial    basis,    one    of examples, TNO pharma (2004)    has taken up the challenge of toxicogenomics.

A    research program is initiated with the following features;

Embedding    in    "classical"    toxicology:    comparison    of multiple     gene     expression     and     proteome     changes induced in vivo as a function of time and dose level.

Use of in vitro systems to underscore in vivo findings

(but not the other way around!).

Integrated     genomics     and     proteomics     analysis     of

target organs.

Incorporation    of    kinetics    and    metabolism    in    target

organ toxicity assessment.

Evaluation of possible polymorphisms in the mechanism of toxicity, and the consequences for extrapolation to the human situation.

Combination     of     tissue     microdissection     and     gene expression    analysis    in    order    to    relate    pathology    and genomics.

Comparison of gene expression changes to a toxicogenomics database to allow for classification of the effects.

A proprietary pathway related bioinformatics    system

aiding the toxicologist in understanding the data.

Complex    data    analysis    based    on    pattern    recognition

and proprietary principle component analysis.

First grade technology ("home-made"    high    density DNA     arrays,     2D-proteomics     with     MALDI-TOF     and nanospray MS).

Advantages and limitations: There are both advantages and limitations to the use of gene microarray and proteomics technologies in toxicological screening.

The main advantage is a global approach to understanding the complex mechanisms involved in toxicology.

Gene microarrays have been costly and limited in availability, but    the    past    year    has    shown    a    commitment    by    the scientific community to the general use and availability of gene microarrays.

Consequently, cost has been reduced by    increased    supply    and    demand.

Furthermore,    the availability and cost is substantially improving with many universities and research centers establishing genomic and proteomic facilities.

Also recent experiments applied to    cancer    genetics    have    demonstrated    the    potential    of gene expression profiling to accurately classify disease phenotypes (Alizadeh et al., 2000; Bittner et al., 2000), thus lending hope that expression profiling may classify and thus predict phenotypes of toxicity.

Despite these expectations, it is still uncertain how gene expression profiling experiments will ultimately contribute to our understanding of toxicity and allow us to realize the full potential of this new technology.

Pennie et al.

(2000, 2002, 2004) have also discussed the possibilities and caveats of gene expression profiling in the context of mechanistic and predictive toxicology and have addressed the certainty, biological relevance.

Therefore, toxicogenomics    and     proteomics     will    certainly    become generally used technologies in the near future.

Health Risk Assessment and Biomarkers: Biomarkers will play an important role in early detection of environmentally induced    disease,    since    routine    surveillance    programs    in both    human    and    animals    in    suspected    environmentally hazardous areas could be instituted.

Toxicogenomics and proteomics are also providing new biomarkers for

use in human studies.

It is now possible to envision schemes for    integrating    the    results    of    molecular    epidemiological investigations into the general toxicological evaluations of environmental agents.

These will allow intermediate endpoints to be used for making realistic human health assessments    and    for    elucidating    pathogenic    mechanisms that identify targets for intervention, all with the goal of preventing environmentally mediated human disease.

Also, select biomarker responses     that predict the likelihood of disease occurrence will    find application in the    interpretation    of    individual    medical    diagnostic    tests, with the goal of improving cancer detection and management.

The objective is to determine whether gene, protein or metabolite expression profiles or ’’signatures” can serve as markers to predict toxicity.

Current efforts are underway to establish "best choices and practices” and perform proof-of principle experiments to phenotypically anchor altered patterns of expression to conventional parameters of toxicity.

These trials are more closely define the time and dose relationships to express "signatures" that develope tools of predictive toxicology and elucidate common mechanism of toxicity and drug action.

Early detection of toxic exposures is a developing art, but many groups have already successfully classified chemical exposures based on profiling of mRNA from treated animals (Bartosiewicz et aL, 2001a,b;    Hamadeh    et    al.,    2002a,b,c).

This    kind    of information might be useful for risk assessment in that significant changes in expression in a small set of highly discriminatory genes can together act as a biomarker of toxic mechanisms or endpoints.

Toxicoirrfoimatics    :    There    is    more    specified    fields such astoxicoinformatics.

Toxicoinformatics is the important factor of toxicogenomics field.

Toxicoinformatics is essential computational tools for the analysis of time- and dose­ dependent changes in patterns of toxicant-induced gene expression.

Development of these capabilities will require a database that complies high quality data from diverse sources involving different gene expression platforms, assay methods, validation results and diverse drugs, chemicals or environmental agents.

Complete analysis will require linkage between and among additional databases that provide most current sequence identity can annotate gene identify and function, chemical structure, toxicity, pathology, pharmacokinetics/biodistribution, and genotoxicity (Mattes et al., 2004; Mattingly et al., 2004; Olden etal., 2004; Tong et al., 2004).

International Harmonization and QA/QC: To promote the    further    development    and    application    of    the    "omic" technologies    to    toxicology    and    environmental    health    risk assessment,    recently, on    Oct    12-13, Toxicogenomics International    Forum (2004)    was    held, and continuosly, OECD/IPCS organized a special workshop for toxicogenomics focusing eco-toxicogenomics at Kyoto, Japan on Oct 13-15, 2004.

In this OECD/IPCS workshop (2004), 4 group sessions open to discuss the problems and future plan of toxicogenomics,    especially    focused    on    eco- toxicogenomics (Fig.2).

One is biological breakout group and they summarized that toxicogenomic technologies have unique opportunities to address ecological and human health concerns, such as; i) offering possibilities to reduce, refine and replace

costly animal intensive methods for chemical screening and testing, ii) understanding how and why species and subgroups differ in sensitivity and response to chemical stress, and create a stronger scientific foundation for the safety factors.

This will allow effective policies to be developed in order to protect endangered and importance species,    iii)    assessing    the    effects    of    chemical    mixtures and combination of stressors.

Previously, appropriate methods have been lacking, iv) reduced uncertainty in assessment of ecological conditions.

These will allow effective policies to be developed to protect endangered and important species.

For these reasons, it is important that these new tools are evaluated and implemented for chemical risk assessment.

In the technical group, several useful technical tools such as global oligo array, global cDNA array, targeted oligo array, targeted cDNA array, Q-PCR and SAGE for transcriptomics, and 2D-MALDI, 2D-MS/MS, Ciphergen-IVALDI, Protein arrays, LC-MS/MS, ICAT-MALDI, ICAT-MS/MS and ELISA for proteomics, and NMR, targeted MS-based, LC-electrochemical for metabolomics were discussed.

The regulatory usefulness of toxicogenomic    tools    is very important (Frueh et al., 2004).

In this respect, in the regulatory group, expected outcomes are a road map for development, validation and regulatory use of genomic­ based tools, proposals for further activities related to the use of genomic-based methods in chemical assessment and promotion of related research to be undertaken within the OECD Environment, Health and Safety Programme, and proposals for mechanism of international co-ordination     for     the     development,     validation     and regulatory use of genome-based tools.

The bioinformatics group adopted general recommendations such as 1) stable funding and adequate funding must be provided    to    a    national    and    internationals    level    for standardization initiatives, database and tool development and long-term maintenance, 2) provide training in data requirements     and     bioinformatics     issues     relating     to ecotoxicogenomics for risk assessors, 3) governments should promote synergy between the toxicology and ecotoxicology communities, including a trialogue between scientists, regulators and bioinformaticians on an international     scale,     4)     in     the     broader     context     of ecotoxicogenomics studies, initial efforts should be centered on a few species representative of the ecological complexity, and 5) establish a task force/working group to implement    these    recommendations    and    coordinate future actions.

The ultimate promise of toxicogenomics lies in its potential ability; (i) to identify sources of interindividual variability     in     response     to     drugs     and     environmental xenobiotics, both in terms of efficacy and toxicity; This

area    of    research    requires genetics knowledge    regarding individual variation which determines person's responses to drugs and xenobiotics; (ii) to provide a database for the     development     of     high-throughput     and     low-cost platforms for screening substances for toxicity; and (iii) to improve the process of discovering new targets for drug action.

However,     the     high     degree     of     QA/QC     on microarray chips to produce more reliable data will be remained to be solve at present.

As every human being on the earth are unique in their genetic make up, there are huge variations in responses against outer environmental factors and also in susceptibility to a disease.

As the medical research is getting    into    the    arena    of    personalized    medicine    which applies individual's genetic information in disease treatment and selection of drugs, toxicogenomic research also have to look into the individual genetic differences.

A genetic variation which is involved in metabolism of toxicants    and    chemicals    can    answer    the    questions    of why some people    react more sensitively to same environments than      others.

Careful cataloging of association between    genetic background and responses to toxic substances will serve as a    powerful tool to understand toxicological phenomenon.

This way, one can possibly    assess each    individual's risks in a given environment and design a plan to avoid any toxic effects.

Consequently, toxicogenomics will be a great promising next    generation    technology    (Waring    and    Halbert,    2002) in the fields of health risk assessment, drug safety, food safety and forensic toxicology etc.

Additionally, there will a new paradigm that is systems biology.

The confluence of omics, bioinformatics, mechanistic studies at the molecular level, and computational biology has yielded a new discipline called systems biology (Oltvai and Barabasi, 2002)."

Systems biology is a new field of biology that aims to develop a system-level understanding of biological systems(Kitano.002).

It requires collective efforts from multiple research areas, such as molecular biology (genomics), high-precision measurement, computer science, control theory and other scientific and engineering fields.

